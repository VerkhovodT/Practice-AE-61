---
title: "Classification Tree Verkhovod"
output:
  word_document: default
  html_notebook: default
  html_document: default
---

# Download the data
```{r}
set.seed(123)
setwd('C:/Users/VerkhovodTS/Desktop/R')
f <- read.csv2('clients2.csv', header = TRUE, encoding = 'UNICOD')
```
# Splitting the dataset into the TRAIN set and TEST set 
```{r}
set.seed(123) 
library(caTools) 
split = sample.split(f$DELAY, SplitRatio = 0.8) 
f_train = subset(f, split == TRUE) 
f_test = subset(f, split == FALSE) 
```
Висновок: датасет розподілено на навчальну та тестову вибірки.
# Fitting 
```{r}
# install.packages('rpart')
library(rpart)
f_train$DELAY <- as.factor(f_train$DELAY)
f_test$DELAY <- as.factor(f_test$DELAY)
class_dt = rpart(DELAY ~ ., data = f_train)
```
Висновок: базову модель дерева побудовано на основі всіх змінних.
# Predicting
```{r}
y <- predict(class_dt, f_test[-20], type = 'class')
```
Висновок: визначені класи об’єктів (вектор у). 
# Confusion Matrix
```{r}
cm = table(f_test[, 'DELAY'], y)
print(cm)
```
Висновок: точність моделі – (380+182) / 800 = 70.25 %, частка невірно класифікованих випадків – (157+81) / 800 = 29,75 %. Чутливість – 182 / (157+182) = 53,69 %, специфічність – 380 / (380+81) = 82.43 %, тобто модель більш чутлива до виявлення негативних випадків (кредиторів, що мають заборгованість).
Частка вірно класифікованих показників в даній моделі кращий, ніж у всіх попередньо розглянутих. Чутливість та спецефічність моделі також значно кращі.
# Plotting the tree
```{r}
plot(class_dt)
text(class_dt)
```
Висновок: візуалізація дозволяє проаналізувати логіку побудови дерева. Зокрема, позичальники, загальний досвід яких менше за 17,5 років, при отриманні кредиту більше ніж на 729,5 днів (2 роки), ймовірно, затримуватимуть відшкодування кредиту.

# Less features 
```{r}
f <- f[,c( 'LOAN.TERM', 'CLIENT_TOTALEXPERIENCE', 'DELAY')] 
#'LOAN_AMOUNT','CLIENT_TOTALEXPERIENCE', 'CLIENT_TOGETHER.INCOME', 'LOAN_OUTSTANDINGLOANSCOUNT','AGE'
```
Висновок: залишимо для моделювання лише кількісні змінні. 
# Features Scaling 
```{r}
sc <- scale(f[-3])
#f$LOAN_AMOUNT <- sc[,c('LOAN_AMOUNT')] 
f$CLIENT_TOTALEXPERIENCE <- sc[,c('CLIENT_TOTALEXPERIENCE')]
#f$CLIENT_TOGETHER.INCOME <- sc[,c('CLIENT_TOGETHER.INCOME')]
#f$LOAN_OUTSTANDINGLOANSCOUNT <- sc[,c('LOAN_OUTSTANDINGLOANSCOUNT')]
f$LOAN.TERM <- sc[,c('LOAN.TERM')]
#f$AGE <- sc[,c('AGE')]
```
Висновок: проведемо шкалювання кількісних змінних. 
# Splitting the scaled dataset into the TRAIN set and TEST set
```{r}
set.seed(123) 
library(caTools) 
split = sample.split(f$DELAY, SplitRatio = 0.8) 
f_train = subset(f, split == TRUE) 
f_test = subset(f, split == FALSE)
```
Висновок: підготований датасет розподілено на навчальну та тестову вибірки. 
# Fitting 
```{r}
class_ct = rpart(DELAY ~ ., data = f_train) 
```
Висновок: проведено навчання моделі дерева рішень. 
# Predicting 
```{r}
y <- predict(class_ct, f_test[, c('LOAN.TERM', 'CLIENT_TOTALEXPERIENCE')], type = 'class') 
```
Висновок: визначено класи об’єктів (вектор у). Для цього використано параметр type = ‘class’. 
# Confusion Matrix 
```{r}
cm = table(f_test[,'DELAY'], y) 
print(cm) 
```

Висновок: точність моделі – (397+135) / 800 = 66,5 %, частка невірно класифікованих випадків – (204+64) / 800 = 33,5 %. Чутливість – 135 / (204+135) = 39.82 %, специфічність – 397 / (397+64) = 86.12 %, тобто модель більш чутлива до виявлення негативних випадків (клієнтів, що мають заборгованість). 
# Visualising the Test set results 
```{r}
#install.packages("ElemStatLearn") 
library(ElemStatLearn) 
set = f_test[,c('age','income','DELAY')] 
X1 = seq(min(set['age']) - 1, max(set['age']) + 1, by = 0.01) 
X2 = seq(min(set['income']) - 1, max(set['income']) + 1, by = 0.01) 
grid_set = expand.grid(X1, X2) colnames(grid_set) = c('age', 'income') 
y_grid = predict(class_ct, grid_set, type = 'class') 
plot(set[, -3],      main = 'Classification Tree',      
     xlab = 'age',      ylab = 'income',      
     xlim = range(X1), ylim = range(X2)) 
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE) 
points(grid_set, pch = '.', col = ifelse(y_grid == 'YES', 'tomato', 'sprin green3')) 
points(set, pch = 21, bg = ifelse(set[, 3] == 'YES', 'red3', 'green4')) 
```
Висновок: на графіку зеленим позначені випадки затримки з повернення кредиту, червоним – хороші кредитори. Зеленим виділена зона високої ймовірності неповернення кредиту. Модель описує нелінійний варіант розподіляючої кривої. 

#Fitting Random Forest Classification to the Training set 
```{r}
# install.packages(‘randomForest’) 
library(randomForest) 
## randomForest 4.6-14 
## Type rfNews() to see new features/changes/bug fixes. 
set.seed(123) 
class_rf = randomForest(DELAY ~ ., data = f_train, ntree = 50) 
```
Висновок: проведено навчання моделі випадкового лісу. 
# Predicting 
```{r}
y <- predict(class_rf, f_test[, c('LOAN.TERM', 'CLIENT_TOTALEXPERIENCE')], type = 'class') 
```
Висновок: визначені класи об’єктів (вектор у). Для цього використано параметр type = ‘class’. 
##Confusion Matrix 
```{r}
cm = table(f_test[, 'DELAY'], y) 
print(cm) 
```
## Висновок: точність моделі – (86+87) / 200 = 86,5 %, частка невірно класифікованих випадків – (12+15) / 200 = 13,5 %. Чутливість – 87 / (15+87) = 85 %, специфічність – 86 / (86+12) = 88 %, тобто модель показує тіж самі характеристики, що й для дерева рішень, вона більш чутлива до виявлення негативних випадків. У цьому разі – кредиторів, що не мають заборгованості. 

# Visualising the Test set results 
```{r}
set = f_test[,c('LOAN.TERM', 'CLIENT_TOTALEXPERIENCE','DELAY')] 
X1 = seq(min(set['LOAN.TERM']) - 1, max(set['LOAN.TERM']) + 1, by = 0.01) 
X2 = seq(min(set['CLIENT_TOTALEXPERIENCE']) - 1, max(set['CLIENT_TOTALEXPERIENCE']) + 1, by = 0.01) 
grid_set = expand.grid(X1, X2) 
colnames(grid_set) = c('LOAN.TERM', 'CLIENT_TOTALEXPERIENCE') 
y_grid = predict(class_rf, grid_set, type = 'class') 
plot(set[, -3],      main = 'Random Forest',      
xlab = 'LOAN.TERM', ylab = 'CLIENT_TOTALEXPERIENCE',      
xlim = range(X1), ylim = range(X2)) 
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE) 
points(grid_set, pch = '.', col = ifelse(y_grid == 'YES', 'tomato', 'light green')) 
points(set, pch = 21, bg = ifelse(set[, 3] == 'YES', 'red3', 'green4')) 
```
#Висновок: на графіку червоним позначені випадки затримки з повернення кредиту, зеленим – хороші кредитори. Червоним виділена зона високої ймовірності неповернення кредиту. Модель описує нелінійний варіант розподіляючої кривої. 


# Fitting XGBoost to the Training set 
```{r}
# install.packages(‘xgboost’) 
library(xgboost) 
## Warning: package ‘xgboost’ was built under R version 3.6.2 
class_xboost = xgboost(data = as.matrix(f_train[-3]), label = f_train$DELAY, nrounds = 10) 
```
Висновок: проведено навчання моделі XGBoost протягом 10 раундів. 
# Predicting the Test set results 
```{r}
y_pred = predict(class_xboost, newdata = as.matrix(f_test[-3])) 
y_pred = (y_pred >= 0.5) 
```
# Making the Confusion Matrix 
```{r}
cm = table(f_test[, 3], y_pred) 
print(cm) 
```
Висновок: точність моделі – (82+75) / 179 = 87,7 %, частка невірно класифікованих випадків – (16+6) / 179 = 12,3 %. Чутливість – 75 / (16+75) = 82 %, специфічність – 82 / (82+6) = 93 %. 
# Applying k-Fold Cross Validation 
```{r}
# install.packages(‘caret’) 
library(caret) 
folds = createFolds(f_train$DELAY, k = 10) 
cv = lapply(folds, function(x) {   
  train_fold = f_train[-x, ]   
  test_fold = f_train[x, ] 
class_xboost = xgboost(data = as.matrix(f_train[-3]), label = f_train$DELAY, nrounds = 10)   
y_pred = predict(class_xboost, newdata = as.matrix(test_fold[-3]))   
y_pred = (y_pred >= 0.5)  
cm = table(test_fold[, 3], y_pred)   
accuracy = (cm[1,1] + cm[2,2]) / (cm[1,1] + cm[2,2] + cm[1,2] + cm[2,1])   
return(accuracy) 
}) 
accuracy = mean(as.numeric(cv)) 
print(accuracy) 
```

