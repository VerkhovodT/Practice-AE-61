---
title: "LR4_Verkhovod"
output:
  word_document: default
  html_document: default
---
# Decision Tree Regression
```{r}
setwd('C:/Users/VerkhovodTS/Desktop/R/')
f_train <- read.csv2('gdp_train2.csv', header = TRUE, encoding = 'UNICOD')
f_train <- f_train[,-1] 
f_train <- f_train[,-1] 
f_test <- read.csv2('gdp_test2.csv', header = TRUE, encoding = 'UNICOD')
f_test <- f_test[,-1] 
f_test <- f_test[,-1]
```
Висновок: Ми завантажили навчальну і тестову вибірки. Видалили перші 2 стовпчики в кожній з вибірок.
```{r}
library(rpart)
model_dt <- rpart(GDP ~ Population, f_train, control = rpart.control(minsplit = 9))
plot(model_dt)
text(model_dt)
```
Висновок: побудовано дерево рішень, екзогенна змінна – Population

# Predicting
```{r}
p_dt <- predict(model_dt, f_test)
train_mse_dt <- sum((f_train$GDP-predict(model_dt, f_train))^2) /length(f_train$GDP)
test_mse_dt <- sum((f_test$GDP-p_dt)^2)/length(p_dt)
train_mse_dt
test_mse_dt
```
Висновок: значення середньоквадратичної помилки і на навчальній вибірці – 2.590712e+23, і на тестовій вибірці – 2.201086e+23 покращилися, перенавчання немає.

# Visualising
```{r}
library(ggplot2)
x_grid <- seq(min(f_train$Population), max(f_train$Population), 100)
ggplot() +
  geom_point(aes(f_train$Population, f_train$GDP),colour = 'red') +
  geom_point(aes(f_test$Population, f_test$GDP),colour = 'green') +
  geom_line(aes(x_grid, predict(model_dt, data.frame(Population = x_grid))),colour = 'black') +
  ggtitle('GDP vs Population') +
  xlab('Population') +
  ylab('GDP')
```
Висновок: на графіку червоним позначені точки навчальної вибірки, зеленим – точки тестової вибірки, чорна лінія – модельні значення. 

# Random forest
```{r}
library(randomForest)
set.seed(1234)
model_rf = randomForest(x = f_train['Population'],
                  y = f_train$GDP,
                  ntree = 2)
```
# Predicting
```{r}
p_rf <- predict(model_rf, f_test)

train_mse_rf <- sum((f_train$GDP-predict(model_rf, f_train))^2)/length(f_train$GDP)
test_mse_rf <- sum((f_test$GDP-p_rf)^2)/length(p_rf)

train_mse_rf
test_mse_rf
```
Висновок: значення середньоквадратичної помилки на навчальній вибірці погіршилась – 2.649926e+23, на тестовій вибірці – 1.965748e+23 покращилися, немає перенавчання.
# Visualising
```{r}
ggplot() +
  geom_point(aes(f_train$Population, f_train$GDP),colour = 'red') +
  geom_point(aes(f_test$Population, f_test$GDP),colour = 'blue') +
  geom_line(aes(x_grid, predict(model_rf, data.frame(Population = x_grid))),colour = 'black') +
  ggtitle('GDP vs Population') +
  xlab('Population') +
  ylab('GDP')
```
Висновок: на графіку червоним позначені точки навчальної вибірки, синім – точки тестової вибірки, чорна лінія – модельні значення. 
# Saving results
```{r}
fit <- read.csv2('GDP_fit.csv', header = TRUE, encoding = 'UNICOD')
fit$p_dt <- p_dt
fit$p_rf <- p_rf
head(fit)
write.csv2(fit[-1], file = "GDP_fit.csv")
```
Висновок:результати моделювання збережені у файлі.